{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/EnriqueMejia96/chatbot_qa.git"
      ],
      "metadata": {
        "id": "VBxm68xmgill",
        "outputId": "0b2b66d9-19fc-4de5-81b6-8992d3b36ea0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'chatbot_qa'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 11 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (11/11), 745.27 KiB | 5.65 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd chatbot_qa"
      ],
      "metadata": {
        "id": "Q9nlcp-kmBcC",
        "outputId": "0ffabd21-b2ef-4e7b-9b38-87478bd6b2fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/chatbot_qa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la"
      ],
      "metadata": {
        "id": "LNh5ScGhmE3K",
        "outputId": "14ad51e0-218b-4b60-e867-e79a1f74ad01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 956\n",
            "drwxr-xr-x 4 root root   4096 Jan 11 22:14 .\n",
            "drwxr-xr-x 1 root root   4096 Jan 11 22:03 ..\n",
            "-rw-r--r-- 1 root root   2832 Jan 11 21:51 app.py\n",
            "-rw-r--r-- 1 root root     76 Jan 11 22:03 credentials.json\n",
            "-rw-r--r-- 1 root root   3921 Jan 11 21:51 dmc_logo.jpg\n",
            "drwxr-xr-x 8 root root   4096 Jan 11 21:51 .git\n",
            "-rw-r--r-- 1 root root  50192 Jan 11 21:51 Lab_LLM_intro.ipynb\n",
            "-rw-r--r-- 1 root root 885970 Jan 11 21:51 llm_doc.pdf\n",
            "drwxr-xr-x 2 root root   4096 Jan 11 22:14 __pycache__\n",
            "-rw-r--r-- 1 root root     12 Jan 11 21:51 README.md\n",
            "-rw-r--r-- 1 root root   1822 Jan 11 21:51 utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Instalación de librerías"
      ],
      "metadata": {
        "id": "zwvEI5c5fdd6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56NzsFMWE8dr"
      },
      "outputs": [],
      "source": [
        "# !pip install streamlit\n",
        "# !pip install pyngrok==4.1.1\n",
        "# #https://dashboard.ngrok.com/signup\n",
        "# !pip install --upgrade typing_extensions\n",
        "# !pip install openai\n",
        "# !pip install pypdf\n",
        "# !pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Crear Vector Store"
      ],
      "metadata": {
        "id": "XLjT4hG8fj8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Carga de documento pdf"
      ],
      "metadata": {
        "id": "UE39ibAXf5DP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"llm_doc.pdf\")\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "xwsglPNX0FuP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. Generación de 'chunks'"
      ],
      "metadata": {
        "id": "UcyIP8vUf8pn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "documents = loader.load()\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size    = 1000,\n",
        "                                               chunk_overlap = 100)\n",
        "doc_splits = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "ps7um1CM1lpL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_splits[2].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "iuiQATZ42bd6",
        "outputId": "b1a3d801-7929-4328-869c-50562243f141"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.\\nIntroduction to LLMOps\\nGenerative AI models have gained wide popularity in recent times with the adoption of  \\ntransformer-based neural network architectures. Generative model’s ability to generate new data \\nenables them to go beyond traditional prediction and classification use cases. These models \\nare now used across domains and use cases like chatbots, question answering, fraud detection, \\nprotein folding and many more.\\nGenerative AI models for natural language use cases are powered by Large Language Models (LLMs). \\nLLMs are transformer-based Deep Learning architectures that harness vast amounts of textual \\ndata to develop language and domain understanding. The models are built with an emphasis on \\ngenerating human-like responses and reasoning. Their ability to understand human languages allows \\nthem to serve as powerful tools for information retrieval, natural language processing, language \\ntranslation and even creative writing.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_splits[3].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "MaE36ZsriRtq",
        "outputId": "e03244d4-3010-45b7-e476-3656764b11e8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'translation and even creative writing.\\nUsing large language models in production environments poses a certain unique set of challenges \\nsuch as organizing LLMs into agents for sub-tasks, developing robust instructions for each  \\nLLM agent, evaluating the correctness of generated response and efficiencies with fine-tuning.  \\nHence, effective usage in a production environment requires appropriate infrastructure and practices \\nfocusing on experimentation, deployment, management and monitoring of large language models. \\nLarge Language Model Operations (LLMOps) is a framework of tools and best practices  \\nto manage the lifecycle of LLM-powered applications, from development to deployment  \\nand maintenance.\\nThe aim is to enable AI capabilities with LLMs by developing better prompts, longer context, \\nfaster inference and customized techniques that enable rapid experimentation and innovation \\nwith LLMs. Together, these allow data scientists and engineers to collaborate effectively and'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_splits[3].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7n47-kv22eMw",
        "outputId": "e65debf2-856f-4ee4-e23a-2b2652b837d7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': 'llm_doc.pdf', 'page': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. Crear Vector Store como dataframe"
      ],
      "metadata": {
        "id": "8TwUdY3GgMti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = [{'Chunks': doc.page_content, 'Metadata': doc.metadata} for doc in doc_splits]\n",
        "df_vector_store = pd.DataFrame(data)\n",
        "df_vector_store.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZdK8v8_S2CRu",
        "outputId": "abc94f0b-7075-4d15-bb8f-afb2887c1dee"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Chunks  \\\n",
              "0  Building Pipelines and Environments for  \\nLar...   \n",
              "1  Contents\\nIntroduction to LLMOps 1\\nWhy LLMOps...   \n",
              "2  1.\\nIntroduction to LLMOps\\nGenerative AI mode...   \n",
              "3  translation and even creative writing.\\nUsing ...   \n",
              "4  with LLMs. Together, these allow data scientis...   \n",
              "\n",
              "                               Metadata  \n",
              "0  {'source': 'llm_doc.pdf', 'page': 0}  \n",
              "1  {'source': 'llm_doc.pdf', 'page': 1}  \n",
              "2  {'source': 'llm_doc.pdf', 'page': 2}  \n",
              "3  {'source': 'llm_doc.pdf', 'page': 2}  \n",
              "4  {'source': 'llm_doc.pdf', 'page': 2}  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-570d9edf-2843-4173-bc18-165ab5fa9859\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Chunks</th>\n",
              "      <th>Metadata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Building Pipelines and Environments for  \\nLar...</td>\n",
              "      <td>{'source': 'llm_doc.pdf', 'page': 0}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Contents\\nIntroduction to LLMOps 1\\nWhy LLMOps...</td>\n",
              "      <td>{'source': 'llm_doc.pdf', 'page': 1}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.\\nIntroduction to LLMOps\\nGenerative AI mode...</td>\n",
              "      <td>{'source': 'llm_doc.pdf', 'page': 2}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>translation and even creative writing.\\nUsing ...</td>\n",
              "      <td>{'source': 'llm_doc.pdf', 'page': 2}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>with LLMs. Together, these allow data scientis...</td>\n",
              "      <td>{'source': 'llm_doc.pdf', 'page': 2}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-570d9edf-2843-4173-bc18-165ab5fa9859')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-570d9edf-2843-4173-bc18-165ab5fa9859 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-570d9edf-2843-4173-bc18-165ab5fa9859');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-94a79c73-14e5-4a7c-b705-994cd4c2f171\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-94a79c73-14e5-4a7c-b705-994cd4c2f171')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-94a79c73-14e5-4a7c-b705-994cd4c2f171 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "from google.colab import userdata\n",
        "client = OpenAI(api_key=userdata.get('openai_key'))\n",
        "\n",
        "def text_embedding(text=[]):\n",
        "    embeddings = client.embeddings.create(model=\"text-embedding-ada-002\",\n",
        "                                          input=text,\n",
        "                                          encoding_format=\"float\")\n",
        "    return embeddings.data[0].embedding\n",
        "\n",
        "df_vector_store[\"Embedding\"] = df_vector_store[\"Chunks\"].apply(lambda x: text_embedding([x]))\n",
        "df_vector_store[\"Embedding\"] = df_vector_store[\"Embedding\"].apply(np.array)\n",
        "\n",
        "df_vector_store.to_pickle('df_vector_store.pkl')\n",
        "df_vector_store.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ituYrA4H4hv0",
        "outputId": "ac2101ff-e035-4076-b635-3a1389b8c464"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Chunks  \\\n",
              "0  Building Pipelines and Environments for  \\nLar...   \n",
              "1  Contents\\nIntroduction to LLMOps 1\\nWhy LLMOps...   \n",
              "2  1.\\nIntroduction to LLMOps\\nGenerative AI mode...   \n",
              "3  translation and even creative writing.\\nUsing ...   \n",
              "4  with LLMs. Together, these allow data scientis...   \n",
              "\n",
              "                               Metadata  \\\n",
              "0  {'source': 'llm_doc.pdf', 'page': 0}   \n",
              "1  {'source': 'llm_doc.pdf', 'page': 1}   \n",
              "2  {'source': 'llm_doc.pdf', 'page': 2}   \n",
              "3  {'source': 'llm_doc.pdf', 'page': 2}   \n",
              "4  {'source': 'llm_doc.pdf', 'page': 2}   \n",
              "\n",
              "                                           Embedding  \n",
              "0  [-0.0004000346, -0.012532205, 0.017549334, -0....  \n",
              "1  [0.0031110481, -0.0044141663, -0.0021332903, -...  \n",
              "2  [-0.020828877, -0.008388099, -0.013470776, -0....  \n",
              "3  [-0.006481511, -0.005626922, -0.0033462602, -0...  \n",
              "4  [0.0069767754, -0.0102603715, 0.0035248334, -0...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6aaff17-f195-4085-b1b3-fef32ba78899\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Chunks</th>\n",
              "      <th>Metadata</th>\n",
              "      <th>Embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Building Pipelines and Environments for  \\nLar...</td>\n",
              "      <td>{'source': 'llm_doc.pdf', 'page': 0}</td>\n",
              "      <td>[-0.0004000346, -0.012532205, 0.017549334, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Contents\\nIntroduction to LLMOps 1\\nWhy LLMOps...</td>\n",
              "      <td>{'source': 'llm_doc.pdf', 'page': 1}</td>\n",
              "      <td>[0.0031110481, -0.0044141663, -0.0021332903, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.\\nIntroduction to LLMOps\\nGenerative AI mode...</td>\n",
              "      <td>{'source': 'llm_doc.pdf', 'page': 2}</td>\n",
              "      <td>[-0.020828877, -0.008388099, -0.013470776, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>translation and even creative writing.\\nUsing ...</td>\n",
              "      <td>{'source': 'llm_doc.pdf', 'page': 2}</td>\n",
              "      <td>[-0.006481511, -0.005626922, -0.0033462602, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>with LLMs. Together, these allow data scientis...</td>\n",
              "      <td>{'source': 'llm_doc.pdf', 'page': 2}</td>\n",
              "      <td>[0.0069767754, -0.0102603715, 0.0035248334, -0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6aaff17-f195-4085-b1b3-fef32ba78899')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a6aaff17-f195-4085-b1b3-fef32ba78899 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a6aaff17-f195-4085-b1b3-fef32ba78899');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-89a91a5f-5068-47f5-beb7-7d8b17267338\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-89a91a5f-5068-47f5-beb7-7d8b17267338')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-89a91a5f-5068-47f5-beb7-7d8b17267338 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.  Formulación de pregunta"
      ],
      "metadata": {
        "id": "qc5XZd_lhdey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = '¿Cómo se selecciona un modelo llm?'\n",
        "query_embedding = text_embedding(query)\n",
        "query_embedding"
      ],
      "metadata": {
        "id": "SSrfqvArhd3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Búsqueda semántica"
      ],
      "metadata": {
        "id": "4cjrwgq0jJgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dot_product(row):\n",
        "    return np.dot(row, query_vector)\n",
        "\n",
        "def cosine_similarity(row):\n",
        "    denominator1 = np.linalg.norm(row)\n",
        "    denominator2 = np.linalg.norm(query_vector.ravel())\n",
        "    dot_prod = np.dot(row, query_vector)\n",
        "    return dot_prod/(denominator1*denominator2)\n",
        "\n",
        "def get_context_from_query(query, vector_store, n_chunks = 5):\n",
        "    global query_vector\n",
        "    query_vector = np.array(query_embedding)\n",
        "    top_matched = (\n",
        "        vector_store[\"Embedding\"]\n",
        "        .apply(cosine_similarity)\n",
        "        .sort_values(ascending=False)[:n_chunks]\n",
        "        .index)\n",
        "    top_matched_df = vector_store[vector_store.index.isin(top_matched)][[\"Chunks\"]]\n",
        "    return list(top_matched_df['Chunks'])\n",
        "\n",
        "Context_List = get_context_from_query(\n",
        "    query        = query,\n",
        "    vector_store = df_vector_store,\n",
        "    n_chunks     = 5)\n",
        "\n",
        "for chunk in Context_List:\n",
        "  print(\"#########################\")\n",
        "  print(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bimLQjun3Vsf",
        "outputId": "a4603ad3-f4da-4b5b-f7d2-a54f7a399860"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#########################\n",
            "Contents\n",
            "Introduction to LLMOps 1\n",
            "Why LLMOps? 1\n",
            "Typical stages in an LLMOps Workflow 2\n",
            " 3.1 Data Collection, Preparation, Labelling 2\n",
            " 3.2 Selection of Foundation Models 3\n",
            " 3.3 Using Large Language Models - Prompting and Fine-tuning 4\n",
            " 3.4 Evaluation of Prompts and Models & Version Control 5\n",
            " 3.5 Deployment and Monitoring 6\n",
            " 3.6 Security, Privacy, Governance and Ethical Considerations 8\n",
            "Setting Up LLMOps Pipelines 9\n",
            "Conclusions 11\n",
            "References 11\n",
            "#########################\n",
            "translation and even creative writing.\n",
            "Using large language models in production environments poses a certain unique set of challenges \n",
            "such as organizing LLMs into agents for sub-tasks, developing robust instructions for each  \n",
            "LLM agent, evaluating the correctness of generated response and efficiencies with fine-tuning.  \n",
            "Hence, effective usage in a production environment requires appropriate infrastructure and practices \n",
            "focusing on experimentation, deployment, management and monitoring of large language models. \n",
            "Large Language Model Operations (LLMOps) is a framework of tools and best practices  \n",
            "to manage the lifecycle of LLM-powered applications, from development to deployment  \n",
            "and maintenance.\n",
            "The aim is to enable AI capabilities with LLMs by developing better prompts, longer context, \n",
            "faster inference and customized techniques that enable rapid experimentation and innovation \n",
            "with LLMs. Together, these allow data scientists and engineers to collaborate effectively and\n",
            "#########################\n",
            "|  33.2 Selection of Foundation Models \n",
            "Since training LLMs from scratch is costly and time-consuming, requiring enormous amounts of \n",
            "data and computational resources, many researchers and practitioners opt to use pre-trained LLMs \n",
            "as foundation models, which can be fine-tuned or adapted to specific downstream applications \n",
            "with less data and resources. \n",
            "Some popular foundation models include BERT, GPT-3, T5 and XLNet. These models have been \n",
            "shown to be effective for a wide range of tasks including natural language understanding, natural \n",
            "language generation and machine translation. \n",
            "Different foundation models have different strengths and weaknesses depending on their \n",
            "architecture, pre-training data and learning objectives. It is important to carefully consider the \n",
            "different factors when selecting a foundation model for an LLM project, some points that can be \n",
            "considered are:\n",
            "• Performance of model on benchmark tasks\n",
            "#########################\n",
            "available to run on less expensive hardware. \n",
            "• Availability of domain-specific pre-trained models\n",
            " Domain-specific models are foundational models that are specialized for tasks that can be   \n",
            " selected as per use cases. Some examples are BloombergGPT which is trained on  a wide  \n",
            " range of financial data for the financial industry, Med-PaLM2 and BioMedLM which are   \n",
            " aligned to the medical domain to answer medical questions more accurately and safely.   \n",
            " Galactica which is an LLM fine-tuned with scientific knowledge.\n",
            "• Licensing terms of the foundation model\n",
            " One of the key factors that influence the choice of an LLM is the licensing and availability  \n",
            " of the model. Many organizations can opt for a managed model service provided by various   \n",
            " vendors where for a flat fee they get a fully managed deployment service and technical  \n",
            " support with only the option to fine-tune. Another option is to use an open-source model\n",
            "#########################\n",
            "permitted to perform and may potentially reveal sensitive data .\n",
            "The uncontrolled deployment of LLMs could lead to the generation of biased, offensive or \n",
            "discriminatory content. Proper governance mechanisms are necessary to ensure that the outputs \n",
            "of these models align with ethical standards and do not perpetuate harmful biases. LLMs can \n",
            "inadvertently generate content that promotes hate speech, violence or misinformation.\n",
            "Since these models are trained on large and diverse datasets, inherent biases present in the \n",
            "training data can lead to biased outputs and since many users may not fully understand how the \n",
            "model arrives at specific conclusions, making it difficult to assess the reliability and credibility of the \n",
            "generated content as well.\n",
            "Generating content with LLMs could raise concerns about intellectual property rights. \n",
            "Determining ownership and authorship of generated texts can be challenging, especially when \n",
            "the model incorporates a vast corpus of publicly available data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Construir prompt"
      ],
      "metadata": {
        "id": "_Xv0An1qkDnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_prompt = \"\"\"\n",
        "Eres una Inteligencia Artificial super avanzada que trabaja asistente personal.\n",
        "Utilice los RESULTADOS DE BÚSQUEDA SEMANTICA para responder las preguntas del usuario.\n",
        "Solo debes utilizar la informacion de la BUSQUEDA SEMANTICA si es que hace sentido y tiene relacion con la pregunta del usuario.\n",
        "Si la respuesta no se encuentra dentro del contexto de la búsqueda semántica, no inventes una respuesta, y responde amablemente que no tienes información para responder.\n",
        "\n",
        "RESULTADOS DE BÚSQUEDA SEMANTICA:\n",
        "{source}\n",
        "\n",
        "Lee cuidadosamente las instrucciones, respira profundo y escribe una respuesta para el usuario!\n",
        "\"\"\".format(source = str(Context_List))"
      ],
      "metadata": {
        "id": "UOlfbajEkJUb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Obtener respuesta"
      ],
      "metadata": {
        "id": "aRFvTqrlk0Aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=userdata.get('openai_key'))\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-4\",\n",
        "  temperature = 0.0,\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": custom_prompt},\n",
        "    {\"role\": \"user\", \"content\": query}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Senk7tcn0b_l",
        "outputId": "2a2e8c29-c09e-4cab-cdae-0cf156ca9bdc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La selección de un modelo de Lenguaje de Gran Escala (LLM, por sus siglas en inglés) implica varios factores. Primero, dado que entrenar LLMs desde cero es costoso y consume mucho tiempo, muchos investigadores y profesionales optan por usar LLMs preentrenados como modelos base, que pueden ser ajustados o adaptados a aplicaciones específicas con menos datos y recursos. Algunos modelos base populares incluyen BERT, GPT-3, T5 y XLNet.\n",
            "\n",
            "Al seleccionar un modelo base para un proyecto LLM, es importante considerar varios factores:\n",
            "\n",
            "1. Rendimiento del modelo en tareas de referencia.\n",
            "2. Disponibilidad para ejecutarse en hardware menos costoso.\n",
            "3. Disponibilidad de modelos preentrenados específicos del dominio. Estos son modelos base que están especializados para tareas que pueden ser seleccionadas según los casos de uso. Algunos ejemplos son BloombergGPT, que está entrenado en una amplia gama de datos financieros para la industria financiera, y Med-PaLM2 y BioMedLM, que están alineados con el dominio médico para responder preguntas médicas de manera más precisa y segura.\n",
            "4. Términos de licencia del modelo base. Un factor clave que influye en la elección de un LLM es la licencia y disponibilidad del modelo. Muchas organizaciones pueden optar por un servicio de modelo gestionado proporcionado por varios proveedores, donde por una tarifa plana obtienen un servicio de despliegue totalmente gestionado y soporte técnico con la opción de ajustar el modelo. Otra opción es usar un modelo de código abierto.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Ejecutar Streamlit App"
      ],
      "metadata": {
        "id": "gwj-zxtmk-zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from pyngrok import ngrok\n",
        "ngrok_token = userdata.get('ngrok_token')\n",
        "!ngrok authtoken $ngrok_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9xAs5jSQJRE",
        "outputId": "c5d8b72e-ed81-44c0-e0f2-82ff1a4a9863"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup streamlit run app.py &\n",
        "public_url = ngrok.connect(port='8501')\n",
        "public_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "pi5GqYjBOnL6",
        "outputId": "8281143f-5f76-4e92-8176-ffad58bea448"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'http://6f19-34-68-3-131.ngrok-free.app'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Terminate all active ngrok tunnels\n",
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "YTfemLpjQz_Z"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Naba_SX5n1e-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}