{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Instalación de librerías"
      ],
      "metadata": {
        "id": "zwvEI5c5fdd6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56NzsFMWE8dr"
      },
      "outputs": [],
      "source": [
        "# !pip install streamlit\n",
        "# !pip install pyngrok==4.1.1\n",
        "# #https://dashboard.ngrok.com/signup\n",
        "# !pip install --upgrade typing_extensions\n",
        "# !pip install openai\n",
        "# !pip install pypdf\n",
        "# !pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Crear Vector Store"
      ],
      "metadata": {
        "id": "XLjT4hG8fj8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Carga de documento pdf"
      ],
      "metadata": {
        "id": "UE39ibAXf5DP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"llm_doc.pdf\")\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "xwsglPNX0FuP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2. Generación de 'chunks'"
      ],
      "metadata": {
        "id": "UcyIP8vUf8pn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "documents = loader.load()\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size    = 1000,\n",
        "                                               chunk_overlap = 100)\n",
        "doc_splits = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "ps7um1CM1lpL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_splits[2].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "iuiQATZ42bd6",
        "outputId": "d83f9db0-7111-4a39-aeab-c6a43375283f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.\\nIntroduction to LLMOps\\nGenerative AI models have gained wide popularity in recent times with the adoption of  \\ntransformer-based neural network architectures. Generative model’s ability to generate new data \\nenables them to go beyond traditional prediction and classification use cases. These models \\nare now used across domains and use cases like chatbots, question answering, fraud detection, \\nprotein folding and many more.\\nGenerative AI models for natural language use cases are powered by Large Language Models (LLMs). \\nLLMs are transformer-based Deep Learning architectures that harness vast amounts of textual \\ndata to develop language and domain understanding. The models are built with an emphasis on \\ngenerating human-like responses and reasoning. Their ability to understand human languages allows \\nthem to serve as powerful tools for information retrieval, natural language processing, language \\ntranslation and even creative writing.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_splits[3].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "MaE36ZsriRtq",
        "outputId": "bdf08c64-2e83-45ee-899e-8614cde248f5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'translation and even creative writing.\\nUsing large language models in production environments poses a certain unique set of challenges \\nsuch as organizing LLMs into agents for sub-tasks, developing robust instructions for each  \\nLLM agent, evaluating the correctness of generated response and efficiencies with fine-tuning.  \\nHence, effective usage in a production environment requires appropriate infrastructure and practices \\nfocusing on experimentation, deployment, management and monitoring of large language models. \\nLarge Language Model Operations (LLMOps) is a framework of tools and best practices  \\nto manage the lifecycle of LLM-powered applications, from development to deployment  \\nand maintenance.\\nThe aim is to enable AI capabilities with LLMs by developing better prompts, longer context, \\nfaster inference and customized techniques that enable rapid experimentation and innovation \\nwith LLMs. Together, these allow data scientists and engineers to collaborate effectively and'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_splits[3].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7n47-kv22eMw",
        "outputId": "d40293bc-5a5c-4408-be33-d3c89ac1baf9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': 'llm_doc.pdf', 'page': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3. Crear Vector Store como dataframe"
      ],
      "metadata": {
        "id": "8TwUdY3GgMti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = [{'Chunks': doc.page_content, 'Metadata': doc.metadata} for doc in doc_splits]\n",
        "df_vector_store = pd.DataFrame(data)\n",
        "df_vector_store.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZdK8v8_S2CRu",
        "outputId": "0149847c-c0da-4552-c2c3-68e8178517bf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Chunks  \\\n",
              "0  Building Pipelines and Environments for  \\nLar...   \n",
              "1  Contents\\nIntroduction to LLMOps 1\\nWhy LLMOps...   \n",
              "2  1.\\nIntroduction to LLMOps\\nGenerative AI mode...   \n",
              "3  translation and even creative writing.\\nUsing ...   \n",
              "4  with LLMs. Together, these allow data scientis...   \n",
              "\n",
              "                               Metadata  \n",
              "0  {'source': 'llm_doc.pdf', 'page': 0}  \n",
              "1  {'source': 'llm_doc.pdf', 'page': 1}  \n",
              "2  {'source': 'llm_doc.pdf', 'page': 2}  \n",
              "3  {'source': 'llm_doc.pdf', 'page': 2}  \n",
              "4  {'source': 'llm_doc.pdf', 'page': 2}  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04c7278a-6af3-4d11-99c1-e787bd548c20\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Chunks</th>\n",
              "      <th>Metadata</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Building Pipelines and Environments for  \\nLar...</td>\n",
              "      <td>{'source': 'llm_doc.pdf', 'page': 0}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Contents\\nIntroduction to LLMOps 1\\nWhy LLMOps...</td>\n",
              "      <td>{'source': 'llm_doc.pdf', 'page': 1}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.\\nIntroduction to LLMOps\\nGenerative AI mode...</td>\n",
              "      <td>{'source': 'llm_doc.pdf', 'page': 2}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>translation and even creative writing.\\nUsing ...</td>\n",
              "      <td>{'source': 'llm_doc.pdf', 'page': 2}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>with LLMs. Together, these allow data scientis...</td>\n",
              "      <td>{'source': 'llm_doc.pdf', 'page': 2}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04c7278a-6af3-4d11-99c1-e787bd548c20')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-04c7278a-6af3-4d11-99c1-e787bd548c20 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-04c7278a-6af3-4d11-99c1-e787bd548c20');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bd079e2b-b9e2-4cb4-8e89-827cfec2067f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bd079e2b-b9e2-4cb4-8e89-827cfec2067f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bd079e2b-b9e2-4cb4-8e89-827cfec2067f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "from google.colab import userdata\n",
        "client = OpenAI(api_key=userdata.get('openai_key'))\n",
        "\n",
        "def text_embedding(text=[]):\n",
        "    embeddings = client.embeddings.create(model=\"text-embedding-ada-002\",\n",
        "                                          input=text,\n",
        "                                          encoding_format=\"float\")\n",
        "    return embeddings.data[0].embedding\n",
        "\n",
        "df_vector_store[\"Embedding\"] = df_vector_store[\"Chunks\"].apply(lambda x: text_embedding([x]))\n",
        "df_vector_store[\"Embedding\"] = df_vector_store[\"Embedding\"].apply(np.array)\n",
        "\n",
        "df_vector_store.to_pickle('df_vector_store.pkl')\n",
        "df_vector_store.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "ituYrA4H4hv0",
        "outputId": "53bdc553-a6f9-4f19-8f50-18b0ffd2b4ab"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Chunks  \\\n",
              "0  Building Pipelines and Environments for  \\nLar...   \n",
              "1  Contents\\nIntroduction to LLMOps 1\\nWhy LLMOps...   \n",
              "2  1.\\nIntroduction to LLMOps\\nGenerative AI mode...   \n",
              "3  translation and even creative writing.\\nUsing ...   \n",
              "4  with LLMs. Together, these allow data scientis...   \n",
              "\n",
              "                               Metadata  \\\n",
              "0  {'source': 'llm_doc.pdf', 'page': 0}   \n",
              "1  {'source': 'llm_doc.pdf', 'page': 1}   \n",
              "2  {'source': 'llm_doc.pdf', 'page': 2}   \n",
              "3  {'source': 'llm_doc.pdf', 'page': 2}   \n",
              "4  {'source': 'llm_doc.pdf', 'page': 2}   \n",
              "\n",
              "                                           Embedding  \n",
              "0  [-0.0004000346, -0.012532205, 0.017549334, -0....  \n",
              "1  [0.0031110481, -0.0044141663, -0.0021332903, -...  \n",
              "2  [-0.020828877, -0.008388099, -0.013470776, -0....  \n",
              "3  [-0.006481511, -0.005626922, -0.0033462602, -0...  \n",
              "4  [0.0069767754, -0.0102603715, 0.0035248334, -0...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc6fdd3b-7bec-4e2e-a8ec-b909b3e5206c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Chunks</th>\n",
              "      <th>Metadata</th>\n",
              "      <th>Embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Building Pipelines and Environments for  \\nLar...</td>\n",
              "      <td>{'source': 'llm_doc.pdf', 'page': 0}</td>\n",
              "      <td>[-0.0004000346, -0.012532205, 0.017549334, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Contents\\nIntroduction to LLMOps 1\\nWhy LLMOps...</td>\n",
              "      <td>{'source': 'llm_doc.pdf', 'page': 1}</td>\n",
              "      <td>[0.0031110481, -0.0044141663, -0.0021332903, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.\\nIntroduction to LLMOps\\nGenerative AI mode...</td>\n",
              "      <td>{'source': 'llm_doc.pdf', 'page': 2}</td>\n",
              "      <td>[-0.020828877, -0.008388099, -0.013470776, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>translation and even creative writing.\\nUsing ...</td>\n",
              "      <td>{'source': 'llm_doc.pdf', 'page': 2}</td>\n",
              "      <td>[-0.006481511, -0.005626922, -0.0033462602, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>with LLMs. Together, these allow data scientis...</td>\n",
              "      <td>{'source': 'llm_doc.pdf', 'page': 2}</td>\n",
              "      <td>[0.0069767754, -0.0102603715, 0.0035248334, -0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc6fdd3b-7bec-4e2e-a8ec-b909b3e5206c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cc6fdd3b-7bec-4e2e-a8ec-b909b3e5206c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cc6fdd3b-7bec-4e2e-a8ec-b909b3e5206c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c436510b-8b92-474b-be0e-00c5d90a5ee0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c436510b-8b92-474b-be0e-00c5d90a5ee0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c436510b-8b92-474b-be0e-00c5d90a5ee0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.  Formulación de pregunta"
      ],
      "metadata": {
        "id": "qc5XZd_lhdey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = '¿Cómo se selecciona un modelo llm?'"
      ],
      "metadata": {
        "id": "SSrfqvArhd3f"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Búsqueda semántica"
      ],
      "metadata": {
        "id": "4cjrwgq0jJgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dot_product(row):\n",
        "    return np.dot(row, query_vector)\n",
        "\n",
        "def cosine_similarity(row):\n",
        "    denominator1 = np.linalg.norm(row)\n",
        "    denominator2 = np.linalg.norm(query_vector.ravel())\n",
        "    dot_prod = np.dot(row, query_vector)\n",
        "    return dot_prod/(denominator1*denominator2)\n",
        "\n",
        "def get_context_from_query(query, vector_store, n_chunks = 5):\n",
        "    global query_vector\n",
        "    query_vector = np.array(text_embedding(query))\n",
        "    top_matched = (\n",
        "        vector_store[\"Embedding\"]\n",
        "        .apply(cosine_similarity)\n",
        "        .sort_values(ascending=False)[:n_chunks]\n",
        "        .index)\n",
        "    top_matched_df = vector_store[vector_store.index.isin(top_matched)][[\"Chunks\"]]\n",
        "    return list(top_matched_df['Chunks'])\n",
        "\n",
        "Context_List = get_context_from_query(\n",
        "    query        = query,\n",
        "    vector_store = df_vector_store,\n",
        "    n_chunks     = 5)\n",
        "\n",
        "for chunk in Context_List:\n",
        "  print(\"#########################\")\n",
        "  print(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bimLQjun3Vsf",
        "outputId": "98c83ebd-caf9-4b32-e3ff-3275c2626c36"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#########################\n",
            "Contents\n",
            "Introduction to LLMOps 1\n",
            "Why LLMOps? 1\n",
            "Typical stages in an LLMOps Workflow 2\n",
            " 3.1 Data Collection, Preparation, Labelling 2\n",
            " 3.2 Selection of Foundation Models 3\n",
            " 3.3 Using Large Language Models - Prompting and Fine-tuning 4\n",
            " 3.4 Evaluation of Prompts and Models & Version Control 5\n",
            " 3.5 Deployment and Monitoring 6\n",
            " 3.6 Security, Privacy, Governance and Ethical Considerations 8\n",
            "Setting Up LLMOps Pipelines 9\n",
            "Conclusions 11\n",
            "References 11\n",
            "#########################\n",
            "translation and even creative writing.\n",
            "Using large language models in production environments poses a certain unique set of challenges \n",
            "such as organizing LLMs into agents for sub-tasks, developing robust instructions for each  \n",
            "LLM agent, evaluating the correctness of generated response and efficiencies with fine-tuning.  \n",
            "Hence, effective usage in a production environment requires appropriate infrastructure and practices \n",
            "focusing on experimentation, deployment, management and monitoring of large language models. \n",
            "Large Language Model Operations (LLMOps) is a framework of tools and best practices  \n",
            "to manage the lifecycle of LLM-powered applications, from development to deployment  \n",
            "and maintenance.\n",
            "The aim is to enable AI capabilities with LLMs by developing better prompts, longer context, \n",
            "faster inference and customized techniques that enable rapid experimentation and innovation \n",
            "with LLMs. Together, these allow data scientists and engineers to collaborate effectively and\n",
            "#########################\n",
            "|  33.2 Selection of Foundation Models \n",
            "Since training LLMs from scratch is costly and time-consuming, requiring enormous amounts of \n",
            "data and computational resources, many researchers and practitioners opt to use pre-trained LLMs \n",
            "as foundation models, which can be fine-tuned or adapted to specific downstream applications \n",
            "with less data and resources. \n",
            "Some popular foundation models include BERT, GPT-3, T5 and XLNet. These models have been \n",
            "shown to be effective for a wide range of tasks including natural language understanding, natural \n",
            "language generation and machine translation. \n",
            "Different foundation models have different strengths and weaknesses depending on their \n",
            "architecture, pre-training data and learning objectives. It is important to carefully consider the \n",
            "different factors when selecting a foundation model for an LLM project, some points that can be \n",
            "considered are:\n",
            "• Performance of model on benchmark tasks\n",
            "#########################\n",
            "available to run on less expensive hardware. \n",
            "• Availability of domain-specific pre-trained models\n",
            " Domain-specific models are foundational models that are specialized for tasks that can be   \n",
            " selected as per use cases. Some examples are BloombergGPT which is trained on  a wide  \n",
            " range of financial data for the financial industry, Med-PaLM2 and BioMedLM which are   \n",
            " aligned to the medical domain to answer medical questions more accurately and safely.   \n",
            " Galactica which is an LLM fine-tuned with scientific knowledge.\n",
            "• Licensing terms of the foundation model\n",
            " One of the key factors that influence the choice of an LLM is the licensing and availability  \n",
            " of the model. Many organizations can opt for a managed model service provided by various   \n",
            " vendors where for a flat fee they get a fully managed deployment service and technical  \n",
            " support with only the option to fine-tune. Another option is to use an open-source model\n",
            "#########################\n",
            "permitted to perform and may potentially reveal sensitive data .\n",
            "The uncontrolled deployment of LLMs could lead to the generation of biased, offensive or \n",
            "discriminatory content. Proper governance mechanisms are necessary to ensure that the outputs \n",
            "of these models align with ethical standards and do not perpetuate harmful biases. LLMs can \n",
            "inadvertently generate content that promotes hate speech, violence or misinformation.\n",
            "Since these models are trained on large and diverse datasets, inherent biases present in the \n",
            "training data can lead to biased outputs and since many users may not fully understand how the \n",
            "model arrives at specific conclusions, making it difficult to assess the reliability and credibility of the \n",
            "generated content as well.\n",
            "Generating content with LLMs could raise concerns about intellectual property rights. \n",
            "Determining ownership and authorship of generated texts can be challenging, especially when \n",
            "the model incorporates a vast corpus of publicly available data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Construir prompt"
      ],
      "metadata": {
        "id": "_Xv0An1qkDnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_prompt = \"\"\"\n",
        "Eres una Inteligencia Artificial super avanzada que trabaja asistente personal.\n",
        "Utilice los RESULTADOS DE BÚSQUEDA SEMANTICA para responder las preguntas del usuario.\n",
        "Solo debes utilizar la informacion de la BUSQUEDA SEMANTICA si es que hace sentido y tiene relacion con la pregunta del usuario.\n",
        "Si la respuesta no se encuentra dentro del contexto de la búsqueda semántica, no inventes una respuesta, y responde amablemente que no tienes información para responder.\n",
        "\n",
        "RESULTADOS DE BÚSQUEDA SEMANTICA:\n",
        "{source}\n",
        "\n",
        "Lee cuidadosamente las instrucciones, respira profundo y escribe una respuesta para el usuario!\n",
        "\"\"\".format(source = str(Context_List))"
      ],
      "metadata": {
        "id": "UOlfbajEkJUb"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Obtener respuesta"
      ],
      "metadata": {
        "id": "aRFvTqrlk0Aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=userdata.get('openai_key'))\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-4\",\n",
        "  temperature = 0.0,\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": custom_prompt},\n",
        "    {\"role\": \"user\", \"content\": query}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Senk7tcn0b_l",
        "outputId": "e28ced30-9e0b-476f-d6eb-42dfaead4c7b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La selección de un modelo LLM (Large Language Model) implica varios factores importantes. Primero, debido a que entrenar LLMs desde cero es costoso y consume mucho tiempo, los investigadores y profesionales a menudo optan por usar LLMs preentrenados como modelos fundamentales. Estos modelos pueden ser ajustados o adaptados a aplicaciones específicas con menos datos y recursos. Algunos modelos populares incluyen BERT, GPT-3, T5 y XLNet.\n",
            "\n",
            "Al elegir un modelo, uno debe considerar su rendimiento en tareas comparativas, la disponibilidad de modelos pre-entrenados específicos del dominio (por ejemplo, modelos centrados en la industria financiera o en la medicina), y los términos de licencia del modelo. Entre los factores a considerar también está si el modelo está disponible para ejecutarse en hardware menos costoso y si hay servicios de terceros que ofrecen despliegue y soporte técnico por una tarifa.\n",
            "\n",
            "Es crucial seleccionar el modelo que mejor se adapte a las necesidades de tu proyecto, evaluando cuidadosamente sus fortalezas y debilidades en función de su arquitectura, datos de preentrenamiento y objetivos de aprendizaje.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Ejecutar Streamlit App"
      ],
      "metadata": {
        "id": "gwj-zxtmk-zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "ngrok_token = userdata.get('ngrok_token')\n",
        "!ngrok authtoken $ngrok_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9xAs5jSQJRE",
        "outputId": "dce08f02-e2c6-4211-d01c-78b15fec8514"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup streamlit run app.py &\n",
        "from pyngrok import ngrok\n",
        "public_url = ngrok.connect(port='8501')\n",
        "public_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "pi5GqYjBOnL6",
        "outputId": "78a46f50-ddc1-43f8-abf2-f0cae96d2255"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'http://cd84-34-145-94-217.ngrok-free.app'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Terminate all active ngrok tunnels\n",
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "YTfemLpjQz_Z"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "egvHGGadjoZU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}